{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Run IAM COMPACT locally/interactively\n",
    "\n",
    " The code in this notebook shows how to run IAM COMPACT veting checks for the\n",
    " 1st modelling cycle manually and locally on the users' own computers, without\n",
    " being dependent on the I2AM PARIS web platform.\n",
    "\n",
    " The notebook comes in two formats:\n",
    "   * Extension `.ipynb`: A Jupyter notebook. Requires using a Jupyter notebook\n",
    "     server or a locally running Jupyter notebook kernel.\n",
    "   * Extension `.py`: A standard Python file with cell denoted in comments as\n",
    "     starting with `# %%`. Can be used interactively in Visual Studio Code or\n",
    "     other applications that can run Python files interactively and recognizes\n",
    "     the `# %%` cell delimiter. Can also be imported as a module, in which case\n",
    "     the entire file is run non-interactively from top to bottom, and outputs\n",
    "     become available as module attributes.\n",
    "\n",
    " This notebook is specific to 1st modelling cycle and the model result files\n",
    " that were available on the IAM COMPACT SharePoint in July 2024. This includes\n",
    " code to load and fix issues with those specific files. A separate notebbok\n",
    " file, named `vetting_assessment`, can be used if you want to run the code with\n",
    " other model results in hopefully non-problematic IAMC-formatted Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Setup\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports\n",
    "\n",
    " Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pyam\n",
    "import pandas as pd\n",
    "\n",
    "from iamcompact_vetting.targets.ar6_vetting_targets import (\n",
    "    vetting_targets\n",
    ")\n",
    "from iamcompact_vetting.targets.iamcompact_harmonization_targets import(\n",
    "    IamCompactHarmonizationRatioCriterion,\n",
    "    gdp_pop_harmonization_criterion\n",
    ")\n",
    "from iamcompact_vetting.targets.target_classes import(\n",
    "    CriterionTargetRange,\n",
    ")\n",
    "from iamcompact_vetting.output.base import CriterionTargetRangeOutput\n",
    "from iamcompact_vetting.output.timeseries import (\n",
    "    TimeseriesComparisonFullDataOutput,\n",
    ")\n",
    "from iamcompact_vetting.output.excel import DataFrameExcelWriter\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Set pandas display options\n",
    "\n",
    " We increase the number of rows displayed to make it easier to see full\n",
    " outputs. Decrease or increase as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.min_rows = 250\n",
    "pd.options.display.max_rows = 300\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Get the model/scenario data to be assessed.\n",
    "\n",
    " In the code cell below, add code to load the data you want to assess and\n",
    " assign it to the variable `iam_df`. This can be done either by using\n",
    " `pyam.IamDataFrame` to read from an Excel or CSV file, or by importing\n",
    " your own code that loads and/or processes the data.\n",
    "\n",
    " In this notebook specifically for the 1st modelling cycle, we use import a\n",
    " separate module that loads precompiled data from the Excel files with results\n",
    " from the 1st modelling cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycle1_study_model_outputs.cycle1_results import joint_iamdf\n",
    "\n",
    "iam_df: pyam.IamDataFrame = joint_iamdf\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data processing / fixing data issues\n",
    "\n",
    " In the code cell or cells below, add code to fix any errors in the data that\n",
    " you want to fix or do any necessary processing before running the vetting\n",
    " code. The variable `iam_df` must hold the correct data at the end. Add cells\n",
    " as needed, preferably at least one cell per distinct error being fixed.\n",
    "\n",
    " In this notebook for the 1st modelling cycle, there are several cells that\n",
    " make modifications to units, variable names and other aspects that needed to\n",
    " be adjusted to be compatible with the vetting procedures. Each distinct issue\n",
    " is processed in a separate cell under a distinct header.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Replace faulty unit `MtCO2/yr` with `Mt CO2/yr`\n",
    "\n",
    " The IAMC standard has a space between the mass unit and the gas species name\n",
    " for species-specific mass units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_df = iam_df.rename(\n",
    "    unit={\"MtCO2/yr\": \"Mt CO2/yr\"}\n",
    ")  # pyright: ignore[reportAssignmentType]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Replace `Carbon Capture` with `Carbon Sequestration|CCS` for PROMETHEUS\n",
    "\n",
    " The PROMETHEUS model uses `Carbon Capture` instead of the name\n",
    " `Carbon Sequestration|CCS` used by the `pathways-ensemble-analysis` package\n",
    " and the AR6 models. Rename it here to make sure that we can use\n",
    " `SingleVariableCriterion` for the \"CCS from energy\" vetting criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prometheus_CCS_df: pyam.IamDataFrame = iam_df.filter(\n",
    "    model='PROMETHEUS V1', variable='Carbon Capture*',  # pyright: ignore[reportAssignmentType]\n",
    ")\n",
    "other_df: pyam.IamDataFrame = iam_df.filter(\n",
    "    model='PROMETHEUS V1', variable='Carbon Capture*', keep=False,  # pyright: ignore[reportAssignmentType]\n",
    ")\n",
    "prometheus_rename_dict: dict[str, str] = {\n",
    "    _varname: _varname.replace(\"Carbon Capture\", \"Carbon Sequestration|CCS\")\n",
    "    for _varname in prometheus_CCS_df.variable  # pyright: ignore[reportAssignmentType]\n",
    "}\n",
    "prometheus_CCS_df = prometheus_CCS_df.rename(\n",
    "    variable=prometheus_rename_dict\n",
    ")  # pyright: ignore[reportAssignmentType]\n",
    "iam_df = pyam.concat([other_df, prometheus_CCS_df])\n",
    "\n",
    "if len(iam_df.filter(variable='Carbon Capture*').variable) > 0:\n",
    "    raise RuntimeError('Unexpected `Carbon Capture` variables remaining.')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Replace `Energy & Industrial Processes` with `Energy and Industrial Processes` in variable names.\n",
    "\n",
    " The IAMC standard uses \"and\" in variable names rather than \"&\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_df = iam_df.rename(\n",
    "    variable={\n",
    "        _varname: _varname.replace(\n",
    "            \"Energy & Industrial Processes\", \"Energy and Industrial Processes\"\n",
    "        )\n",
    "        for _varname in iam_df.variable\n",
    "        if 'Energy & Industrial Processes' in _varname\n",
    "    }\n",
    ")  # pyright: ignore[reportAssignmentType]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Define a new variable `Secondary Energy|Electricity|Wind and Solar`\n",
    "\n",
    " One of the AR6 vetting criteria require a single variable for electricity\n",
    " generated from wind and solar. This was not present in the 1st cycle models,\n",
    " so define it by adding up `Secondary Energy|Electricity|Wind` and\n",
    " `Secondary Energy|Electricity|Solar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_df = pyam.concat(\n",
    "    [\n",
    "        iam_df,\n",
    "        iam_df.add(\n",
    "            'Secondary Energy|Electricity|Wind',\n",
    "            'Secondary Energy|Electricity|Solar',\n",
    "            'Secondary Energy|Electricity|Wind and Solar',\n",
    "        )\n",
    "    ]\n",
    ")  # pyright: ignore[reportAssignmentType]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Correct GDP and population unit names\n",
    "\n",
    " GDP variables in the 1st modelling cycle data from some models used currency\n",
    " unit and base-year designations that are now considered non-standard, such\n",
    " as \"\\$US\" or \"US\\$\" instead of \"USD\", putting the base year directly after the\n",
    " currency unit rather than separating them by an underscore, and \"Billion\" with\n",
    " a capital \"B\" instead of \"billion\". The current, correct convention for IAMC\n",
    " formatted files is to use, e.g., \"USD_2010\" or \"USD_2017\" for 2010 and 2017\n",
    " US dollars.\n",
    "\n",
    " For population, some models used \"millions\" plural instead of \"million\", which\n",
    " also needs to be corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_usd_unit_name(s: str) -> str:\n",
    "    usd_unit_name_pattern = re.compile(r\"(?:US\\$|\\$US)\\s*(\\d{4})\")\n",
    "    return usd_unit_name_pattern.sub(r\"USD_\\1\", s)\n",
    "\n",
    "iam_df = iam_df.rename(\n",
    "    unit={\n",
    "        _unit: _replace_usd_unit_name(_unit).replace(\"Billion\", \"billion\")\n",
    "        for _unit in iam_df.filter(variable='*GDP*').unit\n",
    "    } | {\n",
    "        'millions': 'million'\n",
    "    },\n",
    ")  # pyright: ignore[reportAssignmentType, reportOptionalMemberAccess]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Rename unspecified `GDP` variable\n",
    "\n",
    " The TIAM result files in the 1st modelling cycle uses a variable `GDP` without\n",
    " specifying whether it is MER or PPP. For vetting, we assume it's PPP and\n",
    " therefore rename it to `GDP|PPP` so that it will match the reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_df = iam_df.rename(variable={'GDP': 'GDP|PPP'})  # pyright: ignore[reportAssignmentType]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Assess the AR6 vetting ranges\n",
    "\n",
    " The cells below assess whether the results are in range and how far they are\n",
    " from the target value of each vetting criterion.\n",
    "\n",
    " First create lists with DataFrames/Series with the target results and the\n",
    " values returned by `.get_values` for each vetting criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_crit_target: CriterionTargetRange\n",
    "\n",
    "vetting_results: list[pd.DataFrame] = [\n",
    "    _crit_target.get_distances_in_range(iam_df)\n",
    "    for _crit_target in vetting_targets\n",
    "]\n",
    "\n",
    "criterion_values: list[pd.Series] = [\n",
    "    _crit_target.get_values(iam_df)\n",
    "    for _crit_target in vetting_targets\n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then combine the results into single DataFrame/Series.\n",
    "\n",
    " `vetting_results_df` will be a DataFrame with a column `distance` for the\n",
    " distance between the value for a given model/scenario and the target value\n",
    " (in most cases `0` when the value is equal to the target, `+1.0` if it is at\n",
    " the upper limit of the range, and `-1.0` if it is at the lower limit), and\n",
    " a column `in_range` for whether each value is in the target range or not.\n",
    "\n",
    " `criterion_values_series` will be a Series with the same index as\n",
    " `vetting_results_df`, and the values will be the criterion values for each\n",
    " model/scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetting_results_df: pd.DataFrame = pd.concat(vetting_results, axis=\"index\")\n",
    "\n",
    "criterion_values_series: pd.Series = pd.concat(criterion_values, axis=\"index\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then turn `vetting_results_df` and `criterion_values_series` into DataFrames\n",
    " with one column for each vetting criterion, to make it easier to read.\n",
    "\n",
    " `vetting_results_df` will be split into two DataFrames,\n",
    " `vetting_results_in_range_df` and `vetting_results_distance_df`, one for each\n",
    " column in `vetting_results_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetting_results_in_range_df: pd.DataFrame = pd.DataFrame(\n",
    "    data={\n",
    "        _target_name: vetting_results_df[\"in_range\"] \\\n",
    "            .xs(_target_name, level='variable')\n",
    "        for _target_name in vetting_results_df.index.unique(level='variable')\n",
    "    }\n",
    ")\n",
    "\n",
    "vetting_results_distance_df: pd.DataFrame = pd.DataFrame(\n",
    "    data={\n",
    "        _target_name: vetting_results_df[\"distance\"] \\\n",
    "            .xs(_target_name, level='variable')\n",
    "        for _target_name in vetting_results_df.index.unique(level='variable')\n",
    "    }\n",
    ")\n",
    "\n",
    "criterion_values_df: pd.DataFrame = pd.DataFrame(\n",
    "    data={\n",
    "        _target_name: criterion_values_series \\\n",
    "            .xs(_target_name, level='variable')\n",
    "        for _target_name in criterion_values_series.index.unique(level='variable')\n",
    "    }\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Try writing output with a `CriterionRangeTargetOutput` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_valid_excel_sheetname(s: str) -> str:\n",
    "    return s.replace(':', '-') \\\n",
    "        .replace('*', ' ') \\\n",
    "        .replace('/', '|') \\\n",
    "        .replace('\\\\', '|') \\\n",
    "        [0:31]\n",
    "\n",
    "results_excel_writer: pd.ExcelWriter = pd.ExcelWriter(\"vetting_results.xlsx\",\n",
    "                                              engine='xlsxwriter')\n",
    "vetting_results_outputs: list[\n",
    "    CriterionTargetRangeOutput[DataFrameExcelWriter, None]\n",
    "] = [\n",
    "    CriterionTargetRangeOutput(\n",
    "        criteria=_crit_target,\n",
    "        writer=DataFrameExcelWriter(\n",
    "            results_excel_writer,\n",
    "            sheet_name=make_valid_excel_sheetname(_crit_target.name)\n",
    "        )\n",
    "    )\n",
    "    for _crit_target in vetting_targets\n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Write the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _output in vetting_results_outputs:\n",
    "    _output.write_results(iam_df)\n",
    "results_excel_writer.close()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Assess compliance with harmonisation data for population and GDP.\n",
    "\n",
    " *NB!* The current code below is just a test at the moment. First get a\n",
    " `TimeseriesRefCriterion` with the population and GDP data from harmonization,\n",
    " to test whether it works with the model data.\n",
    " assessment_values: pd.Series = \\\n",
    "     gdp_pop_harmonization_criterion.get_values(\n",
    "         iam_df\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting out this code again, in favor of using a Timeseries\n",
    "iam_df_pop_gdp = iam_df.filter(variable=['Population', 'GDP|PPP'])\n",
    "assert iam_df_pop_gdp is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_values: pd.Series = \\\n",
    "    gdp_pop_harmonization_criterion.get_values(iam_df_pop_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "assessment_full_comparison: pd.Series = \\\n",
    "    gdp_pop_harmonization_criterion.compare(iam_df_pop_gdp)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Write harmonization assessment result\n",
    "\n",
    " Test using a `TimesereComparisonFullDataOutput` with a `DataFrameExcelWriter`\n",
    " to output the results to an Excel file.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First create a `DataFrameExcelWriter` instance to write to a suitable Excel\n",
    " file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output_file: Path = \\\n",
    "    Path.cwd() / 'gdp_pop_harmonization_assessment.xlsx'\n",
    "\n",
    "gdp_pop_harmonization_assessment_writer: DataFrameExcelWriter = \\\n",
    "    DataFrameExcelWriter(\n",
    "        file=gdp_pop_harmonization_assessment_output_file,\n",
    "        sheet_name='Results vs harmonization ratio',\n",
    "    )\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then create a `TimeseriesComparisonFullDataOutput` instance with the\n",
    " `DataFrameExcelWriter` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output: TimeseriesComparisonFullDataOutput[\n",
    "    IamCompactHarmonizationRatioCriterion,\n",
    "    DataFrameExcelWriter,\n",
    "    None,\n",
    "] = TimeseriesComparisonFullDataOutput(\n",
    "    criteria=gdp_pop_harmonization_criterion,\n",
    "    writer=gdp_pop_harmonization_assessment_writer\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then write the results to the Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First prepare the output DataFrame for writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_result: pd.DataFrame = \\\n",
    "    gdp_pop_harmonization_assessment_output.prepare_output(iam_df_pop_gdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then write the output DataFrame to the Excel file using the\n",
    " `TimeseriesComparisonFullDataOutput` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output.write_output(\n",
    "    gdp_pop_harmonization_result\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then close the workbook to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdp_pop_harmonization_assessment_output.writer.close()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally do the same, but prepare output and write directly using a\n",
    " `TimeseriesComparisonFullDataOutput` instance, through the `write_results`\n",
    " method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_output_file: Path = gdp_pop_harmonization_assessment_output_file.with_stem(\n",
    "    gdp_pop_harmonization_assessment_output_file.stem + '_direct'\n",
    ")\n",
    "gdp_pop_harmonization_assessment_writer.sheet_name \\\n",
    "    = 'Results vs harmonization direct'\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output_direct: TimeseriesComparisonFullDataOutput[\n",
    "    IamCompactHarmonizationRatioCriterion,\n",
    "    DataFrameExcelWriter,\n",
    "    None,\n",
    "] = TimeseriesComparisonFullDataOutput(\n",
    "    criteria=gdp_pop_harmonization_criterion,\n",
    "    writer=gdp_pop_harmonization_assessment_writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output_direct.write_results(iam_df_pop_gdp)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then close the workbook to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output_direct.writer.close()\n",
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}