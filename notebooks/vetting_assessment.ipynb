{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Run IAM COMPACT locally/interactively\n",
    "\n",
    " The code in this notebook shows how to run IAM COMPACT veting checks for the\n",
    " 1st modelling cycle manually and locally on the users' own computers, without\n",
    " being dependent on the I2AM PARIS web platform.\n",
    "\n",
    " The notebook comes in two formats:\n",
    "   * Extension `.ipynb`: A Jupyter notebook. Requires using a Jupyter notebook\n",
    "     server or a locally running Jupyter notebook kernel.\n",
    "   * Extension `.py`: A standard Python file with cell denoted in comments as\n",
    "     starting with `# %%`. Can be used interactively in Visual Studio Code or\n",
    "     other applications that can run Python files interactively and recognizes\n",
    "     the `# %%` cell delimiter. Can also be imported as a module, in which case\n",
    "     the entire file is run non-interactively from top to bottom, and outputs\n",
    "     become available as module attributes.\n",
    "\n",
    " This notebook is a general notebook for running the 1st modelling cycle\n",
    " vetting checks, and requires you to provide the data you want to assess. To\n",
    " run the notebook with the data from the Excel files that were uploaded to the\n",
    " IAM COMPACT SharePoint with results from select models and studies, see the\n",
    " notebook named `vetting_assessment_1st_modelling_cycle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Setup\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports\n",
    "\n",
    " Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pyam\n",
    "import pandas as pd\n",
    "\n",
    "from iamcompact_vetting.targets.ar6_vetting_targets import (\n",
    "    vetting_targets\n",
    ")\n",
    "from iamcompact_vetting.targets.iamcompact_harmonization_targets import(\n",
    "    IamCompactHarmonizationRatioCriterion,\n",
    "    gdp_pop_harmonization_criterion\n",
    ")\n",
    "from iamcompact_vetting.targets.target_classes import(\n",
    "    CriterionTargetRange,\n",
    ")\n",
    "from iamcompact_vetting.output.base import CriterionTargetRangeOutput\n",
    "from iamcompact_vetting.output.timeseries import (\n",
    "    TimeseriesComparisonFullDataOutput,\n",
    ")\n",
    "from iamcompact_vetting.output.excel import (\n",
    "    DataFrameExcelWriter,\n",
    "    make_valid_excel_sheetname,\n",
    ")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Set pandas display options\n",
    "\n",
    " We increase the number of rows displayed to make it easier to see full\n",
    " outputs. Decrease or increase as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.min_rows = 250\n",
    "pd.options.display.max_rows = 300\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Get the model/scenario data to be assessed.\n",
    "\n",
    " In the code cell below, add code to load the data you want to assess and\n",
    " assign it to the variable `iam_df`. This can be done either by using\n",
    " `pyam.IamDataFrame` to read from an Excel or CSV file, or by importing\n",
    " your own code that loads and/or processes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_df: pyam.IamDataFrame = joint_iamdf\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data processing / fixing data issues\n",
    "\n",
    " In the code cell or cells below, add code to fix any errors in the data that\n",
    " you want to fix or do any necessary processing before running the vetting\n",
    " code. The variable `iam_df` must hold the correct data at the end. Add cells\n",
    " as needed, preferably at least one cell per distinct error being fixed.\n",
    "\n",
    " In this notebook for the 1st modelling cycle, there are several cells that\n",
    " make modifications to units, variable names and other aspects that needed to\n",
    " be adjusted to be compatible with the vetting procedures. Each distinct issue\n",
    " is processed in a separate cell under a distinct header.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fix 1\n",
    "\n",
    " Add the required code in the cell below. Add more cells as needed below this\n",
    " one to organize the code into one cell per distinct fix or processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Assess the AR6 vetting ranges\n",
    "\n",
    " The cells below assess whether the results are in range and how far they are\n",
    " from the target value of each vetting criterion.\n",
    "\n",
    " The procedure uses `vetting_targets`, a list of `CriterionTargetRange`\n",
    " instances, each of which assesses `iam_df` against one of the AR6 vetting\n",
    " criteria. This list is used to produce a list of `CriterionTargetRangeOutput`\n",
    " instances, each of which which uses one of the elements of `vetting_targets`\n",
    " to produce output data structures, each of which are then written to an Excel\n",
    " file using a `DataFrameExcelWriter` instance.\n",
    "\n",
    " The output Excel file will contain one worksheet for each vetting criterion.\n",
    " Each sheet has three index columns, with the name of a model/scenario pair\n",
    " in the first two, and the name of the vetting criterion in the third. The\n",
    " remaining columns are three value columns with vetting results:\n",
    "\n",
    " * `Is in target range`: A boolean value. `TRUE` if the model/scenario passes\n",
    "   the vetting criterion, `FALSE` otherwise.\n",
    " * `Rel. distance from target`: A measure of distance from the central target\n",
    "   value of the vetting criterion. The value is defined differently for each\n",
    "   criterion, and the exact value is not important, but it will generally be\n",
    "   between -1 and +1 for model/scenario pairs that pass the criterion, and\n",
    "   equal to 0 if it exactly hits the central value of the criterion. Values\n",
    "   very close to -1 or +1 indicate that the value of the vetted variable is\n",
    "   almost too low or too high to pass vetting.\n",
    " * `Value`: The value of the vetted variable. See the documentation of the AR6\n",
    "   vetting criteria for which variable or function of variables is evaluated in\n",
    "   each case.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First create a `pandas.ExcelWriter` instance which will write to the output\n",
    " Excel file. We need a common `pandas.ExcelWriter` instance for all of the\n",
    " vetting criteria, so that we can write results to different worksheets of the\n",
    " same Excel file.\n",
    "\n",
    " The cell below creates a `pandas.ExcelWriter` instance that will write to the\n",
    " file `vetting_results.xlsx` in the current working directory. Replace the file\n",
    " name with an alternative one or with a Python `Path` object if you wish to\n",
    " write to a differently named file or to a different directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_excel_writer: pd.ExcelWriter = pd.ExcelWriter(\"vetting_results.xlsx\",\n",
    "                                              engine='xlsxwriter')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then create the list of `CriterionTargetRangeOutput` instances, one for each\n",
    " AR6 vetting criterion. Each instance needs a `DataFrameExcelWriter` instance\n",
    " to write the results to a different worksheet of the same Excel file. The\n",
    " worksheets will have the same name as the corresponding vetting criterion, but\n",
    " with the name potentially shortened and with some characters substituted to\n",
    " make sure that they are valid names for Excel worksheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetting_results_outputs: list[\n",
    "    CriterionTargetRangeOutput[DataFrameExcelWriter, None]\n",
    "] = [\n",
    "    CriterionTargetRangeOutput(\n",
    "        criteria=_crit_target,\n",
    "        writer=DataFrameExcelWriter(\n",
    "            results_excel_writer,\n",
    "            sheet_name=make_valid_excel_sheetname(_crit_target.name)\n",
    "        )\n",
    "    )\n",
    "    for _crit_target in vetting_targets\n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally, we call the `write_results` method of each of the\n",
    " `CriterionTargetRangeOutput` instances, to compute the results and write them\n",
    " to the Excel file.\n",
    "\n",
    " The results are also returned as `pandas.DataFrame` objects in the list\n",
    " `vetting_results_frames`.\n",
    "\n",
    " `results_excel_writer.close()` must be called at the end to close and save the\n",
    " Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetting_results_frames: list[pd.DataFrame] = []\n",
    "for _output in vetting_results_outputs:\n",
    "    _frame, _ = _output.write_results(iam_df)\n",
    "    vetting_results_frames.append(_frame)\n",
    "results_excel_writer.close()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Assess agreement with harmonisation data for population and GDP.\n",
    "\n",
    " The cells below will compare the model results in `iam_df` with the\n",
    " harmonization data for population and GDP in each region that is defined\n",
    " (has the same name) in both the harmonization data and in any of the models\n",
    " in `iam_df`. Note that it does not currently take into account differences\n",
    " in region definitions, or aggregate or translate model-specific region names\n",
    " used in different models. This is intended for a future version.\n",
    "\n",
    " To be assessed, `iam_df` needs to contain population data in a variable named\n",
    " `Population` and GDP data in a variable named `GDP|PPP`. The GDP data must be\n",
    " be in purchasing-power parity terms (PPP), and the unit name must have the\n",
    " form `billion CCC_YYYY/yr`, where `CCC` is the currency code and `YYYY` is the\n",
    " year. For example, `billion USD_2017/yr` for 2017 US dollars (which in this\n",
    " case is also called \"international dollars\", since the GDP should be converted\n",
    " to USD using purchasing-power parity (PPP) rather than market exchange rates\n",
    " (MER).\n",
    "\n",
    " The results are returned as a `pandas.DataFrame` and written to an Excel file\n",
    " as the ratio between the values in `iam_df` relative to the harmonization\n",
    " data, for each data point that exists in both data sets. If a given model and\n",
    " scenario agrees precisely with the harmonization data, the corresponding value\n",
    " in the result will be 1.0. If the model has a smaller or greater value than\n",
    " the harmonization data, the value in the result will be smaller or greater\n",
    " than 1.0, respectively.\n",
    "\n",
    " Generally, for population and GDP, the ratios should be between 0.98 and 1.02\n",
    " to be considered a close match. Values outside that range suggest that either\n",
    " the model/scenario has used data that do not agree with the harmonization\n",
    " data, or that there are issues with currency conversions, region definitions\n",
    " or other inconsistencies or mistakes.\n",
    "\n",
    " First get just the GDP and Population variables from the data. Assert that it\n",
    " is not None (not necessary, but if you use Python with a type checker, it is\n",
    " needed to avoid a warning, since the `IamDataFrame.filter` method can return\n",
    " None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_df_pop_gdp = iam_df.filter(variable=['Population', 'GDP|PPP'])\n",
    "assert iam_df_pop_gdp is not None\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then define a Path to where you want to write an Excel file with the results\n",
    " at the moment it writes it to the file `gdp_pop_harmonization_assessment.xlsx`\n",
    " in the current working directory, but you can change this to your liking.\n",
    " Consult the Python documentation for `pathlib.Path` if you are unfamiliar with\n",
    " how to use Path objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output_file: Path = \\\n",
    "    Path.cwd() / 'gdp_pop_harmonization_assessment.xlsx'\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then create a `DataFrameExcelWriter` instance that will do the actual writing\n",
    " to Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_writer: DataFrameExcelWriter = \\\n",
    "    DataFrameExcelWriter(\n",
    "        file=gdp_pop_harmonization_assessment_output_file,\n",
    "        sheet_name='Results vs harmonization ratio',\n",
    "    )\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define a `TimeseriesComparisonFullDataOutput` instance, which will calculate\n",
    " the results, and use `gdp_pop_harmonization_assessment_writer` to write the\n",
    " results to the Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output: \\\n",
    "    TimeseriesComparisonFullDataOutput[\n",
    "        IamCompactHarmonizationRatioCriterion,\n",
    "        DataFrameExcelWriter,\n",
    "        None,\n",
    "] = TimeseriesComparisonFullDataOutput(\n",
    "    criteria=gdp_pop_harmonization_criterion,\n",
    "    writer=gdp_pop_harmonization_assessment_writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_result, _ignore = \\\n",
    "    gdp_pop_harmonization_assessment_output.write_results(iam_df_pop_gdp)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then close the workbook to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_pop_harmonization_assessment_output.writer.close()\n",
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}